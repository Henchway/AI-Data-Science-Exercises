{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-Puzzle - Analysis of results\n",
    "\n",
    "We're generating unique random puzzles, for which we're assigning 31 different weights per example ranging from 0.7 to 1.0 for the Manhattan distance heuristic and 0.0 to 0.3 for the Hamming distance heuristic.\n",
    "\n",
    "The calculation time is mainly influenced by the depth of the solution path, as well as the mix of the weights of the heuristics. Typically the larger the Hamming distance becomes, the longer the calculation takes, therefore Hamming was capped at 0.3.\n",
    "\n",
    "For the showcase we're taking 1000 unique puzzles, each having 31 weights, which results in 31.000 unique constellations.\n",
    "\n",
    "All data set has the following columns:\n",
    "'array', 'weights', 'visited_nodes', 'expanded_nodes','branching_factor', 'time_elapsed_astar', 'depth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"results_1000_2021-05-05.json\", \"r\") as file:\n",
    "    contents = file.read()\n",
    "    unfrozen = jsonpickle.decode(contents)\n",
    "\n",
    "df = pd.DataFrame(unfrozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('depth', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomenclature\n",
    "\n",
    "(This may be interpreted in a few different ways, so I'll state it here)\n",
    "\n",
    "- Visited Nodes. All nodes in the tree (visited in the sense as actually generated in the code)\n",
    "- Expanded Nodes: All nodes which have children (non-leaf nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle-distribution by depth\n",
    "Group results by depth (= how many steps were required to finish the puzzle), show the distribution of depths as chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "group = df.groupby(['depth'])\n",
    "x_pos = [i for i, _ in enumerate(group)]\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "plt.xticks(list(group.groups.keys()))\n",
    "ax.bar(list(group.groups.keys()), list(group.size()))\n",
    "plt.show()\n",
    "\n",
    "# In all our previous tests it has shown that when using a random generation of puzzles,\n",
    "# a seemingly gaussian distribution of puzzle-depths occurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print constellation for all (average)\n",
    "\n",
    "Shows the average expanded nodes based on the weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average expanded & visited nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "weight_group = df.groupby(['weights'])\n",
    "\n",
    "# Expanded nodes\n",
    "x1 = np.array(list(weight_group.groups.keys()))[:, 0]\n",
    "x2 = np.array(list(weight_group.groups.keys()))[:, 1]\n",
    "y1 = weight_group['expanded_nodes'].mean()\n",
    "\n",
    "# Visited nodes\n",
    "y2 = weight_group['visited_nodes'].mean()\n",
    "\n",
    "# Expanded nodes Manhattan\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[1].set_title(\"Expanded Nodes - Manhattan\")\n",
    "ax[1].plot(x1, y1, \"b--\", label=\"Manhattan weight\")\n",
    "ax[1].set_xlabel(\"Weight ratio\")\n",
    "ax[1].set_ylabel(\"Average expanded nodes\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Expanded nodes Hamming\n",
    "ax[0].set_title(\"Expanded Nodes - Hamming\")\n",
    "ax[0].plot(x2, y1, \"r\", label=\"Hamming weight\")\n",
    "ax[0].set_xlabel(\"Weight ratio\")\n",
    "ax[0].set_ylabel(\"Average expanded nodes\")\n",
    "ax[0].legend()\n",
    "plt.show()\n",
    "\n",
    "# Visited nodes Manhattan\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[1].set_title(\"Visited Nodes - Manhattan\")\n",
    "ax[1].plot(x1, y2, \"g--\", label=\"Manhattan weight\")\n",
    "ax[1].set_xlabel(\"Weight ratio\")\n",
    "ax[1].set_ylabel(\"Average expanded nodes\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Visited nodes Hamming\n",
    "ax[0].set_title(\"Visited Nodes - Hamming\")\n",
    "ax[0].plot(x2, y2, \"m\", label=\"Hamming weight\")\n",
    "ax[0].set_xlabel(\"Weight ratio\")\n",
    "ax[0].set_ylabel(\"Average expanded nodes\")\n",
    "ax[0].legend()\n",
    "plt.show()\n",
    "\n",
    "# We can see that expanded and visited nodes follow a very similar curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Branching factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weight_group = df.groupby(['weights'])\n",
    "\n",
    "# Branching factor\n",
    "x1 = np.array(list(weight_group.groups.keys()))[:, 0]\n",
    "x2 = np.array(list(weight_group.groups.keys()))[:, 1]\n",
    "y1 = weight_group['branching_factor'].mean()\n",
    "y2 = weight_group['branching_factor'].max()\n",
    "y3 = weight_group['branching_factor'].min()\n",
    "\n",
    "\n",
    "# Branching Factor Manhattan\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "ax[1].set_title(\"Branching Factor - Manhattan\")\n",
    "ax[1].plot(x1, y1, \"r--\", label=\"Manhattan - mean\")\n",
    "ax[1].plot(x1, y2, \"g--\", label=\"Manhattan - max\")\n",
    "ax[1].plot(x1, y3, \"b--\", label=\"Manhattan - min\")\n",
    "ax[1].set_xlabel(\"Weight ratio\")\n",
    "ax[1].set_ylabel(\"Branching Factor\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Branching factor Hamming\n",
    "ax[0].set_title(\"Branching Factor - Hamming\")\n",
    "ax[0].plot(x2, y1, \"r\", label=\"Hamming - mean\")\n",
    "ax[0].plot(x2, y2, \"g\", label=\"Hamming - max\")\n",
    "ax[0].plot(x2, y3, \"b\", label=\"Hamming - min\")\n",
    "ax[0].set_xlabel(\"Weight ratio\")\n",
    "ax[0].set_ylabel(\"Branching Factor\")\n",
    "ax[0].legend()\n",
    "plt.show()\n",
    "\n",
    "############### MEAN IN DETAIL ###################\n",
    "\n",
    "# Branching Factor Manhattan\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[1].set_title(\"Branching Factor - Manhattan - Mean\")\n",
    "ax[1].plot(x1, y1, \"b--\", label=\"Manhattan weight\")\n",
    "ax[1].set_xlabel(\"Weight ratio\")\n",
    "ax[1].set_ylabel(\"Average branching Factor\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Expanded nodes Hamming\n",
    "ax[0].set_title(\"Branching Factor - Hamming - Mean\")\n",
    "ax[0].plot(x2, y1, \"r\", label=\"Hamming weight\")\n",
    "ax[0].set_xlabel(\"Weight ratio\")\n",
    "ax[0].set_ylabel(\"Average branching Factor\")\n",
    "ax[0].legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Unexpected finding: The branching factor rises (very slightly) with rising Manhattan ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_value = group[['expanded_nodes']].min()\n",
    "min_value.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "max_value = group[['expanded_nodes']].max()\n",
    "max_value.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best weights based on the least nodes per depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_nodes = df.loc[group['expanded_nodes'].idxmin()]\n",
    "np.mean(min_nodes['weights'].tolist(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_nodes = df.loc[group['visited_nodes'].idxmin()]\n",
    "np.mean(min_nodes['weights'].tolist(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best weights based on the weights with the least nodes of each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "group_by_example = df.groupby('array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_expanded_nodes_per_example = df.loc[group_by_example['expanded_nodes'].idxmin()]\n",
    "np.mean(min_expanded_nodes_per_example['weights'].tolist(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_visited_nodes_per_example = df.loc[group_by_example['visited_nodes'].idxmin()]\n",
    "np.mean(min_visited_nodes_per_example['weights'].tolist(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of examples where Manhattan only ([1.0, 0.0]) is the best choice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded / Visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "manhattan_only_expanded = (min_expanded_nodes_per_example.loc[min_expanded_nodes_per_example['weights'] == (1.0, 0.0)]).shape[0]\n",
    "print(f\"Manhattan only is the best choice in {manhattan_only_expanded}/{min_expanded_nodes_per_example.shape[0]} examples for expanded nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "manhattan_only_visited = (min_visited_nodes_per_example.loc[min_visited_nodes_per_example['weights'] == (1.0, 0.0)]).shape[0]\n",
    "print(f\"Manhattan only is the best choice in {manhattan_only_visited}/{min_visited_nodes_per_example.shape[0]} examples for visited nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best branching factor per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_branching_factor_per_example = df.loc[group_by_example['branching_factor'].idxmin()]\n",
    "np.mean(min_branching_factor_per_example['weights'].tolist(), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}